
Data Engineering 

Data Engineering is about learning concepts, ideas and tools for data storage, tranmission, processing. 

A lot of data Engineer

We learn some concepts and ideas and documnet them here: https://paper.dropbox.com/folder/show/Teach-to-Learn-data-Science-Notes-e.1gg8YzoPEhbTkrhvQwJ2zzo5Gh9Ujml4WfG9jO78hhvjmxzgFm0j

We use notebooks to illustrate  Examples + Code


We have the following goals: 

        1. The Big Picture 
        2. Data Collection (API, Scrapping..)
        3. Data Storage 
                Relational Model  - Relational Database Management Systems (PostGres) 
                Document Model 
                Graph Models 
                Data Lakes 
        4. Data Pipelines
        5. Batch processing (Map Reduce - Apache Spark)
        6. Stream processing 
        

Basics of ETL/Data Pipelines


------------------------------
Interesting data structures
------------------------------

Consistent-Hashing
SSTables and LSM-Trees
B-trees


------------------------------
Data  Collection 
------------------------------

API
web scrapping

------------------------------
Data Storage Models
------------------------------

We Express the data structures in memory as general prupose data models 

1. The Relational Model:

NOTES:  https://paper.dropbox.com/doc/RDMS-Notes--BBr~R~9AS5VpN4MWZfTElfkQAg-B9RVxhqDjWQcOxArwa4YC
CMU NOTES: http://www.datasciencecourse.org/notes/relational_data/ 

2. The Document Model 


3. The Graph Model 


4. JSON/XML 




------------------------------
Dealing with Big data 
------------------------------

-----------------------------
Data Engineering Skills:
-----------------------------

1. Data Modeling
Learn to create relational and NoSQL data models to fit the diverse needs of data consumers. Use ETL to build databases in PostgreSQL and Apache Cassandra.

DATA MODELING WITH POSTGRES
DATA MODELING WITH APACHE CASSANDRA

2. Cloud Data Warehouses
Sharpen your data warehousing skills and deepen your understanding of data infrastructure. 
Create cloud-based data warehouses on Amazon Web Services (AWS).
BUILD A CLOUD DATA WAREHOUSE

3. Spark and Data Lakes
Understand the big data ecosystem and how to use Spark to work with massive datasets. Store big data in a data lake and query it with Spark.
BUILD A DATA LAKE

4. Data Pipelines with Airflow
Schedule, automate, and monitor data pipelines using Apache Airflow. 
Run data quality checks, track data lineage, and work with data pipelines in production.

DATA PIPELINES WITH AIRFLOW


-----------------------------
Data Architect Skills
-----------------------------


Data Architecture Foundations
Learn about the principles of data architecture. You will begin by learning the characteristics of good data architecture and how to apply them. Next you will move on to data modeling. You will learn to design a data model, normalize data, and create a professional ERD. Finally, you will take everything you learned and create a physical database using PostGreSQL.

DESIGNING AN HR DATABASE
Designing Data Systems
Learn to design enterprise data architecture. You will build a cloud based data warehouse with Snowflake. You will evaluate various data assets of an organization and characteristics of these data sources, design a staging area for ingesting varieties of data coming from source systems, and design an Operational Data Store (ODS). Finally, you will learn to design OLAP dimensional data models, design ELT data processing that is capable of moving data from an ODS to a data warehouse, and write SQL queries for the purpose of building reports.

DESIGN A DATA WAREHOUSE FOR REPORTING AND OLAP
Big Data Systems
Learn about how to help organizations with massive amounts of data, including identification of Big Data problems and how to design Big Data solutions. You will learn about the internal architecture of many of the Big Data tools such as HDFS, MapReduce, Hive and Spark, and how these tools work internally to provide distributed storage, distributed processing capabilities, fault tolerance and scalability. Next you will learn how to evaluate NoSQL databases, their use cases and dive deep into creating and updating a NOSQL database with Amazon DynamoDB. Finally, you will learn how to implement Data Lake design patterns and how to enable transactional capabilities in a Data Lake.

DESIGN AN ENTERPRISE DATA LAKE SYSTEM
Data Governance
Learn how to design a data governance solution that meets your companyâ€™s needs. First, you will learn about the different types of metadata, and how to build a Metadata Management System, Enterprise Data Model, and Enterprise Data Catalog. Next you will learn how to perform data profiling using various techniques including data quality dimensions, how to identify remediation options for data quality issues, and how to measure and monitor data quality using data quality scores, thresholds, dashboards, exception and trend reports. Finally, you will learn the concepts of Master Data and golden record, different types of Master Data Management Architectures, as well as the golden record creation and master data governance processes.

DATA GOVERNANCE AT SNEAKERPARK



----------------------------------------------------
resources
----------------------------------------------------

- Classic Graph Algorithms  1/3 of classic CS problems
- https://www.amazon.com.au/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321
- https://github.com/keyvanakbary/learning-notes/blob/master/books/designing-data-intensive-applications.md
- Apache Spark